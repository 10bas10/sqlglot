{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving objects: 100%|██████████| 156/156 [02:25<00:00,  1.08it/s]\n",
      "Transpiling: 100%|██████████| 1231/1231 [04:02<00:00,  5.07it/s]\n",
      "Testing:  75%|███████▍  | 920/1231 [13:15<04:01,  1.29it/s]"
     ]
    }
   ],
   "source": [
    "from sqlglot.vlk.batch import batchTranspile\n",
    "from sqlglot.vlk.repoinventory import Database\n",
    "\n",
    "database_types = (\n",
    "    Database.Type.TRANSFORM,\n",
    "    Database.Type.REFERENCE,\n",
    "    Database.Type.STAGING,\n",
    "    Database.Type.STG_ARCHIVE,\n",
    ")\n",
    "database_filter = lambda x: \"bankview\" in x.lower() or x.lower() == \"reference\"\n",
    "\n",
    "batch = batchTranspile(\n",
    "    root=\"c:/dev/repos/DWH-VLK\",\n",
    "    scope=database_types,\n",
    "    filter=database_filter,\n",
    "    view_metadata_csv=\"metadata/view_metadata.csv\",\n",
    "    db_prefix=\"vl_dwh_\",\n",
    ")\n",
    "\n",
    "batch.transpile()\n",
    "# batch.create_source_tables()\n",
    "batch.test_mappings()\n",
    "batch.report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errortype</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error running query: [COLUMN_NOT_IN_GROUP_BY_CLAUSE] org.apache.spark.sql.AnalysisException: [COLUMN_NOT_IN_GROUP_BY_CLAUSE] The expression \"cd_doelformaat\" is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in `first()` (or `first_value()`) if you don't care which value you get.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Accessing outer query column is not allowed in:</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Correlated column is not allowed in a non-equality predicate:</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Correlated scalar sub-queries can only be used in a Filter/Aggregate/Project and a few commands: Join LeftOuter, ((((1 = 1) AND (dealno#360480 = dealno#360405)) AND (br#360479 = br#360418)) AND (((seq#360494 = payrecind#360410) AND (meta_dt_snapshot#360478 = meta_dt_snapshot#360404)) AND (intenddte#360484 = scalar-subquery#360260 [dealno#360480 &amp;&amp; br#360479 &amp;&amp; seq#360494 &amp;&amp; meta_dt_snapshot#360478])))</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Correlated scalar sub-queries can only be used in a Filter/Aggregate/Project and a few commands: Join LeftOuter, ((((1 = 1) AND (stz#779068 = (1000 * stz#778933))) AND cast(stz#779068 as string) LIKE %000) AND ((zeiger#779071 = scalar-subquery#778754 [stz#779068]) AND ((cast(1900-01-01 00:00:00 as date) &gt;= meta_dt_valid_from#779061) AND (cast(1900-01-01 00:00:00 as date) &lt;= meta_dt_valid_to#779062))))</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Correlated scalar sub-queries can only be used in a Filter/Aggregate/Project and a few commands: Join LeftOuter, ((((1 = 1) AND (stz#779430 = (1000 * stz#779289))) AND cast(stz#779430 as string) LIKE %000) AND ((zeiger#779433 = scalar-subquery#779116 [stz#779430]) AND ((cast(1900-01-01 00:00:00 as date) &gt;= meta_dt_valid_from#779423) AND (cast(1900-01-01 00:00:00 as date) &lt;= meta_dt_valid_to#779424))))</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This function is neither a built-in/temporary function, nor a persistent function that is qualified as hive_metastore.default.eomonth.; line 16 pos 44</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This function is neither a built-in/temporary function, nor a persistent function that is qualified as hive_metastore.default.eomonth.; line 16 pos 7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This function is neither a built-in/temporary function, nor a persistent function that is qualified as hive_metastore.default.eomonth.; line 18 pos 7</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This function is neither a built-in/temporary function, nor a persistent function that is qualified as hive_metastore.default.eomonth.; line 19 pos 4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This function is neither a built-in/temporary function, nor a persistent function that is qualified as hive_metastore.default.eomonth.; line 23 pos 4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This function is neither a built-in/temporary function, nor a persistent function that is qualified as hive_metastore.default.eomonth.; line 30 pos 11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This function is neither a built-in/temporary function, nor a persistent function that is qualified as hive_metastore.default.eomonth.; line 31 pos 11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This function is neither a built-in/temporary function, nor a persistent function that is qualified as hive_metastore.default.eomonth.; line 46 pos 4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This function is neither a built-in/temporary function, nor a persistent function that is qualified as hive_metastore.default.eomonth.; line 71 pos 4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: HASHBYTES. This function is neither a built-in/temporary function, nor a persistent function that is qualified as hive_metastore.default.hashbytes.; line 40 pos 24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: PATINDEX. This function is neither a built-in/temporary function, nor a persistent function that is qualified as hive_metastore.default.patindex.; line 24 pos 8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: SYSDATETIME. This function is neither a built-in/temporary function, nor a persistent function that is qualified as hive_metastore.default.sysdatetime.; line 17 pos 7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_reference.TRN_GETTRANSLATION; line 106 pos 6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_reference.TRN_GETTRANSLATION; line 112 pos 6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: cannot resolve 'timestampdiff(month, 0, CAST(controle.col_rapportage_datum AS TIMESTAMP))' due to data type mismatch: argument 1 requires timestamp type, however, '0' is of int type.; line 31 pos 32</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error running query: org.apache.spark.sql.AnalysisException: cannot resolve 'timestampdiff(month, 0, CAST(controle.col_rapportage_datum AS TIMESTAMP))' due to data type mismatch: argument 1 requires timestamp type, however, '0' is of int type.; line 35 pos 32</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      udf\n",
       "errortype                                                                                                \n",
       "Error running query: [COLUMN_NOT_IN_GROUP_BY_CLAUSE] org.apache.spark.sql.AnalysisException: [COL...    1\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Accessing outer query column is not ...    9\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Correlated column is not allowed in ...    1\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Correlated scalar sub-queries can on...    1\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Correlated scalar sub-queries can on...    1\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Correlated scalar sub-queries can on...    1\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This fu...    5\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This fu...    4\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This fu...    5\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This fu...    5\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This fu...    4\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This fu...    1\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This fu...    1\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This fu...    1\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Undefined function: EOMONTH. This fu...    1\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Undefined function: HASHBYTES. This ...    1\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Undefined function: PATINDEX. This f...    1\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Undefined function: SYSDATETIME. Thi...    4\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_reference...    4\n",
       "Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_reference...    4\n",
       "Error running query: org.apache.spark.sql.AnalysisException: cannot resolve 'timestampdiff(month,...    1\n",
       "Error running query: org.apache.spark.sql.AnalysisException: cannot resolve 'timestampdiff(month,...    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.test_errors.groupby(\"errortype\")[\"udf\"].count().reset_index().set_index(\"errortype\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.transpile_errors[batch.transpile_errors[\"errortype\"].str.startswith(\"Required keyword:\")].to_csv(path_or_buf=\"C:/dev/temp/double_plus.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>schema</th>\n",
       "      <th>table</th>\n",
       "      <th>udf</th>\n",
       "      <th>errortype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>transform_dochtersheets</td>\n",
       "      <td>kco</td>\n",
       "      <td>persoon</td>\n",
       "      <td>udf_persoon_CUSTOMER_RPS</td>\n",
       "      <td>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>transform_dochtersheets</td>\n",
       "      <td>kco</td>\n",
       "      <td>persoon</td>\n",
       "      <td>udf_persoon_CUSTOMER_NPS</td>\n",
       "      <td>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>transform_dochtersheets</td>\n",
       "      <td>oma</td>\n",
       "      <td>persoon</td>\n",
       "      <td>udf_persoon_CUSTOMER_RPS</td>\n",
       "      <td>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>transform_dochtersheets</td>\n",
       "      <td>oma</td>\n",
       "      <td>persoon</td>\n",
       "      <td>udf_persoon_CUSTOMER_NPS</td>\n",
       "      <td>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>transform_dochtersheets</td>\n",
       "      <td>spd</td>\n",
       "      <td>persoon</td>\n",
       "      <td>udf_persoon_CUSTOMER_RPS</td>\n",
       "      <td>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>transform_dochtersheets</td>\n",
       "      <td>spd</td>\n",
       "      <td>persoon</td>\n",
       "      <td>udf_persoon_CUSTOMER_NPS</td>\n",
       "      <td>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>transform_dochtersheets</td>\n",
       "      <td>vch</td>\n",
       "      <td>persoon</td>\n",
       "      <td>udf_persoon_CUSTOMER_RPS</td>\n",
       "      <td>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>transform_dochtersheets</td>\n",
       "      <td>vch</td>\n",
       "      <td>persoon</td>\n",
       "      <td>udf_persoon_CUSTOMER_NPS</td>\n",
       "      <td>Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   database schema    table                       udf  \\\n",
       "26  transform_dochtersheets    kco  persoon  udf_persoon_CUSTOMER_RPS   \n",
       "27  transform_dochtersheets    kco  persoon  udf_persoon_CUSTOMER_NPS   \n",
       "34  transform_dochtersheets    oma  persoon  udf_persoon_CUSTOMER_RPS   \n",
       "35  transform_dochtersheets    oma  persoon  udf_persoon_CUSTOMER_NPS   \n",
       "40  transform_dochtersheets    spd  persoon  udf_persoon_CUSTOMER_RPS   \n",
       "41  transform_dochtersheets    spd  persoon  udf_persoon_CUSTOMER_NPS   \n",
       "42  transform_dochtersheets    vch  persoon  udf_persoon_CUSTOMER_RPS   \n",
       "43  transform_dochtersheets    vch  persoon  udf_persoon_CUSTOMER_NPS   \n",
       "\n",
       "                                                                                              errortype  \n",
       "26  Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...  \n",
       "27  Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...  \n",
       "34  Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...  \n",
       "35  Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...  \n",
       "40  Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...  \n",
       "41  Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...  \n",
       "42  Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...  \n",
       "43  Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_referenc...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.test_errors[batch.test_errors[\"errortype\"].str.startswith(\"Error running query: org.apache.spark.sql.AnalysisException: Undefined function: vl_dwh_reference.TRN_GETTRANSLATION\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c50f91e6729354fc5ae1a48ac2e88f75833758f219ffb46f2b32fda8786c335"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
